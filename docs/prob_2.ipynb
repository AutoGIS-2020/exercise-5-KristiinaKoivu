{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-290-0b670219a956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes_grid1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_axes_locatable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moffline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "### Create interactive map of residents living within 400 - 1600 m (+ 250 m because of the grid resolution) walking distance from \n",
    "### metro and train station in Finland's capital region with a value slider. Data for the map is loaded from open data services of \n",
    "### Maanmittauslaitos (MML) and Helsinki Region Environmental Services Authority (HSY).\n",
    "\n",
    "### IMPORT DATA ###\n",
    "\n",
    "# Import modules\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from geopandas.tools import geocode\n",
    "import numpy as np\n",
    "from pyproj import CRS\n",
    "import requests\n",
    "import geojson\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import cascaded_union\n",
    "import mapclassify\n",
    "import contextily as ctx\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "\n",
    "## Read shape file containing the capital region as polygons into variable 'grid' (Data from https://tiedostopalvelu.maanmittauslaitos.fi/tp/kartta)\n",
    "# File path\n",
    "fp_grid = \"data/pkseutu.shp\"\n",
    "\n",
    "# Read in data\n",
    "grid = gpd.read_file(fp_grid)\n",
    "\n",
    "# Check if crs is correct and set crs to ETRS89 / TM35FIN if the crs is not defined correctly\n",
    "if (grid.crs != \"epsg:3067\"):    \n",
    "    grid = grid.set_crs(epsg=3067)\n",
    "# Reproject to WGS 84 / Pseudo-Mercator if the crs is not defined correctly\n",
    "if (grid.crs != \"epsg:3857\"):    \n",
    "    grid = grid.to_crs(epsg=3857)\n",
    "\n",
    "# Combine polygons of each city to form one polygon of the whole capial region\n",
    "grid['constant'] = 0\n",
    "boundary = grid.dissolve(by='constant')\n",
    "\n",
    "# Check the data\n",
    "print(grid.head())\n",
    "print(grid.crs)\n",
    "print(boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read population grid data for 2018 into a variable `pop`. \n",
    "\n",
    "# Specify the url for web feature service\n",
    "url = 'https://kartta.hsy.fi/geoserver/wfs'\n",
    "\n",
    "# Specify parameters (read data in json format).\n",
    "params = dict(service='WFS',\n",
    "              version='2.0.0',\n",
    "              request='GetFeature',\n",
    "              typeName='asuminen_ja_maankaytto:Vaestotietoruudukko_2018',\n",
    "              outputFormat='json')\n",
    "\n",
    "# Fetch data from WFS using requests\n",
    "r = requests.get(url, params=params)\n",
    "\n",
    "# Create GeoDataFrame from geojson\n",
    "pop = gpd.GeoDataFrame.from_features(geojson.loads(r.content))\n",
    "\n",
    "# Clean out unnecessary columns\n",
    "pop = pop[[\"asukkaita\", \"geometry\"]]\n",
    "\n",
    "# Set crs to ETRS89 / GK25FIN and reproject to WGS 84 / Pseudo-Mercator if the crs is not defined correctly\n",
    "if (pop.crs == None):    \n",
    "    pop = pop.set_crs(epsg=3879)\n",
    "if (pop.crs != \"epsg:3857\"):    \n",
    "    pop = pop.to_crs(epsg=3857)\n",
    "\n",
    "# Check the data\n",
    "print(pop.head())\n",
    "print(pop.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read buffer polygons that describe 400 m, 800 m, 1200 m and 1600 m accessibilities via pedestrian and bicycle ways from metro and \n",
    "## train stations \n",
    "\n",
    "# Save wanted buffer sizes in a list which is used in loading the data\n",
    "dists = ['400', '800', '1200', '1600']\n",
    "\n",
    "# Create an empty geopandas GeoDataFrame for the data\n",
    "buffs = gpd.GeoDataFrame()\n",
    "\n",
    "# Iterate through wanted buffer distance list\n",
    "for dist in dists:\n",
    "\n",
    "    # Specify the url for web feature service and typeName of the data layer\n",
    "    url_buff = 'https://kartta.hsy.fi/geoserver/wfs'\n",
    "    type_name = dist + 'm_verkostobufferi'\n",
    "\n",
    "    # Specify parameters (read data in json format).\n",
    "    params_buff = dict(service='WFS',\n",
    "                  version='2.0.0',\n",
    "                  request='GetFeature',\n",
    "                  typeName=type_name,\n",
    "                  outputFormat='json')\n",
    "\n",
    "    # Fetch data from WFS using requests\n",
    "    r = requests.get(url_buff, params=params_buff)\n",
    "\n",
    "    # Create GeoDataFrame from geojson\n",
    "    buff = gpd.GeoDataFrame.from_features(geojson.loads(r.content))\n",
    "\n",
    "    # Clean out unnecessary columns\n",
    "    buff = buff[[\"asema\", \"geometry\"]]\n",
    "\n",
    "    # Set crs to ETRS89 / GK25FIN and reproject to WGS 84 / Pseudo-Mercator if the crs is not defined correctly\n",
    "    if (buff.crs == None):    \n",
    "        buff = buff.set_crs(epsg=3879)\n",
    "    if (buff.crs != \"epsg:3857\"):    \n",
    "        buff = buff.to_crs(epsg=3857)\n",
    "\n",
    "    # Clip out stations that are located outside the capital region\n",
    "    clip_mask = buff.within(boundary.at[0,'geometry'])\n",
    "    buff = buff.loc[clip_mask]\n",
    "    \n",
    "    # Create column which indicates buffer distance for the slider\n",
    "    buff['dist'] = dist\n",
    "\n",
    "    # Check the data\n",
    "    print(buff.head(1))\n",
    "    print(len(buff))\n",
    "\n",
    "    # Add the data to combined GeoDataFrame\n",
    "    buffs = buffs.append(buff)\n",
    "    \n",
    "# Check output of the loop\n",
    "buffs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PROCESS DATA ###\n",
    "\n",
    "# Create new column to 'buffs' where total resident amounts within each buffer areas are stored \n",
    "buffs[\"residents_sum\"] = None\n",
    "\n",
    "# Create a spatial join between grid layer and buffer layer. \"Intersects\" option used here to include all grid cells which \n",
    "# touch the buffer area (NOTE that with this choice the accuracy of the buffers is lost due to the grid resolution)\n",
    "pop_combined = gpd.sjoin(pop, buffs, how=\"left\", op=\"intersects\")\n",
    "\n",
    "# Group the data by both train and metro station names AND distance classes\n",
    "groupedA = pop_combined.groupby(['asema','dist'])\n",
    "\n",
    "#buffs.head()\n",
    "#pop_combined.head()\n",
    "groupedA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store sum of residents living approximately 400 m, 800 m, 1200 m and 1600 m from station to column \"sum\" \n",
    "# (the distance doesn't stay constant in performed analysis but accurate enough for this visualization)\n",
    "for name, group in groupedA:\n",
    "    buffs.loc[(buffs[\"asema\"]==name[0]) & (buffs['dist']==name[1]),'residents_sum'] = group[\"asukkaita\"].agg(\"sum\")\n",
    "    \n",
    "    \n",
    "## Convert the buffer polygons to points (location set as centroids of 400 m buffers, approximate of the station locations)\n",
    "point_data = buffs\n",
    "point_data = point_data.reset_index()\n",
    "\n",
    "# Replace NoData in residents_sum column with 0\n",
    "point_data[\"residents_sum\"] = point_data[\"residents_sum\"].replace(to_replace=np.nan, value=0)\n",
    "\n",
    "# Group the data by only train and metro station names\n",
    "groupedB = point_data.groupby('asema')\n",
    "#firsts = groupedB.first()\n",
    "\n",
    "# Convert to points based on centroids\n",
    "for name, group in groupedB:\n",
    "    point_data.loc[point_data[\"asema\"]==name,'geometry'] = group['geometry'].centroid\n",
    "\n",
    "point_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          geometry        asema  residents_sum dist\n",
      "0  POINT (2777053.880 8448898.363)       Käpylä           1252  400\n",
      "1  POINT (2779412.695 8470148.966)   Lentoasema              0  400\n",
      "2  POINT (2788489.108 8467666.897)  Hiekkaharju           1920  400\n",
      "3  POINT (2776435.063 8438154.680)     Helsinki            885  400\n",
      "4  POINT (2769199.228 8453290.280)   Kannelmäki           7698  400\n"
     ]
    }
   ],
   "source": [
    "# Assign same point (centroid of 400 m buffer polygon) for each data row of same stations\n",
    "#for i, row in point_data.iterrows():\n",
    "    #new_point = point_data.loc[(point_data['asema']==row[0]) & (point_data['dist']=='400'), 'geometry']\n",
    "    #print(row[3])\n",
    "    #print(i)\n",
    "    #if (row[3] != '400'):\n",
    "        #point_data.at[i, 'geometry'] = point_data.loc[(point_data['asema']==row[0]) & (point_data['dist']=='400'), 'geometry']\n",
    "\n",
    "        \n",
    "# Reorganize the column order\n",
    "point_data = point_data[[\"geometry\",\"asema\",\"residents_sum\", \"dist\"]]\n",
    "\n",
    "    \n",
    "# Check data    \n",
    "print(point_data.head())\n",
    "#type(point_data)\n",
    "#firsts.head()\n",
    "#type(firsts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(point_data.loc[(point_data['dist']=='400') & (point_data['asema']=='Malmi')])\n",
    "print(point_data.loc[(point_data['dist']=='800') & (point_data['asema']=='Malmi')])\n",
    "print(point_data.loc[(point_data['dist']=='1200') & (point_data['asema']=='Malmi')])\n",
    "print(point_data.loc[(point_data['dist']=='1600') & (point_data['asema']=='Malmi')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE PLOT with slider\n",
    "\n",
    "# Create colorscale:    \n",
    "scl = [[0.0, '#ffffff'],[0.2, '#ff9999'],[0.4, '#ff4d4d'], \\\n",
    "       [0.6, '#ff1a1a'],[0.8, '#cc0000'],[1.0, '#4d0000']] # reds\n",
    "\n",
    "# Create empty list for data object:    \n",
    "data_slider = []\n",
    "\n",
    "\n",
    "for distance in point_data.dist.unique():\n",
    "\n",
    "\n",
    "    # Select data of only one distance \n",
    "    data_seg = point_data[point_data['dist']==distance]\n",
    "\n",
    "    # Transform the columns into string \n",
    "    #for col in data_seg.columns:  \n",
    "     #   data_seg[col] = data_seg[col].astype(str)\n",
    "\n",
    "    # Create the text for mouse-hover  \n",
    "    #data_seg['ase'] = df_sected_crime['State'] + \n",
    "    #'Pop: ' /span> df_sected_crime['Population']'Murder rate: '+df_sected_crime['Murder_per100000']\n",
    "\n",
    "    # Create dictionary with the data for the current distance \n",
    "    data_one_dist = dict(\n",
    "                        type='choropleth',\n",
    "                        locations=data_seg['geometry'],\n",
    "                        z=data_seg['residents_sum'].astype(float),\n",
    "                        locationmode='ISO-3',\n",
    "                        colorscale = scl,\n",
    "                        text = data_seg['asema'],\n",
    "                        )\n",
    "\n",
    "    data_slider.append(data_one_dist)  # Add dictionary to the list of dictionaries for the slider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the steps for slider\n",
    "steps = []\n",
    "\n",
    "for i in range(len(data_slider)):\n",
    "    step = dict(method='restyle',\n",
    "                args=['visible', [False] * len(data_slider)],\n",
    "                label='Walking distance from train or metro station {}'.format((i+1)*400)) # label to be displayed for each step (year)\n",
    "    step['args'][1][i] = True\n",
    "    steps.append(step)\n",
    "\n",
    "# Create the 'sliders' object from the 'steps' \n",
    "sliders = [dict(active=0, pad={\"t\": 1}, steps=steps)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the layout \n",
    "layout = dict(geo=dict(scope='usa',\n",
    "                       projection={'type': 'albers usa'}),\n",
    "              sliders=sliders)\n",
    "\n",
    "# Create the figure object:\n",
    "fig = dict(data=data_slider, layout=layout) \n",
    "\n",
    "# Plot in the notebook\n",
    "plotly.offline.iplot(fig)\n",
    "\n",
    "# Plot in a separete browser window\n",
    "#offline.plot(fig, auto_open=True, image = 'png', image_filename=\"map_us_crime_slider\" ,image_width=2000, image_height=1000, \n",
    "              filename='/your_path/map_us_crime_slider.html', validate=True\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
